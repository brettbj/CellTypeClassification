{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.0dev1.dev-fa327997673c637b16e98d726417c8c304dd7b2f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "print(theano.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "(19800, 128, 128, 3)\n",
      "(19800,)\n",
      "(19800, 3, 128, 128)\n",
      "(19800,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "directory = './Images/'\n",
    "# input image dimensions\n",
    "# img_rows, img_cols = 1024, 1024\n",
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "patch_count = 100\n",
    "\n",
    "def load(seed=123):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for i in [2, 4]:\n",
    "        cur_direct = directory + 'Cluster ' + str(i) + '/'\n",
    "        j = 0\n",
    "        label = i/2-1\n",
    "        print(label)\n",
    "        for jpg in os.listdir(cur_direct):\n",
    "            j += 1\n",
    "            \n",
    "            x = ndimage.imread(cur_direct + jpg)\n",
    "            patches = extract_patches_2d(x, (img_rows, img_cols), patch_count)\n",
    "    \n",
    "            if j < 10:\n",
    "                X_test.extend(patches)\n",
    "                \n",
    "                y_test.extend([label] * patch_count)\n",
    "            else:\n",
    "                X.extend(patches)\n",
    "                y.extend([label] * patch_count)\n",
    "\n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y = np.asarray(y)\n",
    "    y_test = np.asarray(y_test)\n",
    "    \n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    X = X.reshape(X.shape[0], 3, img_rows, img_cols)\n",
    "    X, y = shuffle(X, y, random_state=seed)  # shuffle train data\n",
    "    \n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    \n",
    "    X = X.astype('float32')\n",
    "    y = y.astype('float32')\n",
    "    \n",
    "    X_test = X_test.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "    return (X, y, X_test, y_test)\n",
    "\n",
    "X, y, X_test, y_test = load()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (19800, 3, 128, 128))\n",
      "(19800, 'train samples')\n",
      "(1800, 'test samples')\n",
      "((19800,), (1800,))\n",
      "[ 0.  1.]\n",
      "[ 0.  1.]\n",
      "Epoch 1/100\n",
      "19800/19800 [==============================] - 72s - loss: 1.1900 - acc: 0.5484 - val_loss: 0.7007 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "19800/19800 [==============================] - 71s - loss: 0.6510 - acc: 0.5912 - val_loss: 0.7058 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "19800/19800 [==============================] - 71s - loss: 0.6239 - acc: 0.6361 - val_loss: 0.7359 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6480 - acc: 0.5981 - val_loss: 0.7138 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.5238 - acc: 0.7477 - val_loss: 0.7996 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.7229 - acc: 0.5051 - val_loss: 0.6949 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6934 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6932 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6932 - acc: 0.5051 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6932 - acc: 0.5051 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 25/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 26/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 28/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 29/100\n",
      "19800/19800 [==============================] - 74s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 30/100\n",
      "19800/19800 [==============================] - 74s - loss: 0.6861 - acc: 0.5289 - val_loss: 0.6936 - val_acc: 0.5000\n",
      "Epoch 31/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6424 - acc: 0.5993 - val_loss: 0.7029 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6823 - acc: 0.5360 - val_loss: 0.6944 - val_acc: 0.5000\n",
      "Epoch 33/100\n",
      "19800/19800 [==============================] - 74s - loss: 0.6932 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 35/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6930 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 39/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6660 - acc: 0.5636 - val_loss: 0.6997 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6945 - acc: 0.5051 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 41/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 42/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 43/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 44/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 45/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 46/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 47/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 48/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5037 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 49/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 50/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 51/100\n",
      "19800/19800 [==============================] - 74s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 52/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 53/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 54/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 55/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 56/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 57/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 58/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 59/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 60/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 61/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 62/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 63/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 64/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 65/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5001 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 66/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 67/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 68/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 69/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 70/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 71/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 72/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 73/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 74/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 75/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 76/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 77/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6932 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 78/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 79/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6932 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 80/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6932 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 81/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6932 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 82/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 83/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 84/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 85/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 86/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 87/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6932 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 88/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5021 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 89/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 90/100\n",
      "19800/19800 [==============================] - 74s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 91/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 92/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6932 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 93/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 94/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 95/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6932 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 96/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 97/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 98/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 99/100\n",
      "19800/19800 [==============================] - 72s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 100/100\n",
      "19800/19800 [==============================] - 73s - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "('Metrics', ['loss', 'acc'])\n",
      "('Test score:', 0.69325050804350108)\n",
      "('Test accuracy:', 0.5)\n",
      "[0.5]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "\n",
    "nb_classes = 2\n",
    "accuracy = []\n",
    "nb_epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "X_train = X\n",
    "X_test = X_test\n",
    "y_train = y\n",
    "y_test = y_test\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "print(np.unique(y_train))\n",
    "print(np.unique(y_test))\n",
    "# convert class vectors to binary class matrices\n",
    "# Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "# Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "Y_train = y_train\n",
    "Y_test = y_test\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same',\n",
    "                        input_shape=(3, img_rows, img_cols)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=True)  # randomly flip images\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# fit the model on the batches generated by datagen.flow()\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                    samples_per_epoch=X_train.shape[0],\n",
    "                    nb_epoch=nb_epochs,\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    nb_worker=1)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Metrics', model.metrics_names)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "accuracy.append(score[1])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
