{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0.dev-9d0c52b9254c0d30dacbf1e2a231112ee3e3b99a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "print(theano.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69400, 128, 128, 3)\n",
      "(69400,)\n",
      "(69400, 3, 128, 128)\n",
      "(69400,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "directory = './Images/'\n",
    "# input image dimensions\n",
    "# img_rows, img_cols = 1024, 1024\n",
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "patch_count = 200\n",
    "\n",
    "def load(seed=123):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(5):\n",
    "        cur_direct = directory + 'Cluster ' + str(i + 1) + '/'\n",
    "        for jpg in os.listdir(cur_direct):\n",
    "            x = ndimage.imread(cur_direct + jpg)\n",
    "#             x -= np.mean(x)\n",
    "            patches = extract_patches_2d(x, (img_rows, img_cols), patch_count)\n",
    "#             print(patches.shape)\n",
    "            X.extend(patches)\n",
    "#             print(np.asarray(X).shape)\n",
    "            # Flatten for simpler models, don't want to do this for CNN\n",
    "#             X.append((ndimage.imread(cur_direct + jpg, flatten=True)/255.).flatten())\n",
    "#             X.append(imresize((ndimage.imread(cur_direct + jpg, flatten=False)/255.), (img_rows, img_cols)))\n",
    "            y.extend([i] * patch_count)\n",
    "#             print(np.asarray(y).shape)\n",
    "            \n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    X = X.reshape(X.shape[0], 3, img_rows, img_cols)\n",
    "    X, y = shuffle(X, y, random_state=seed)  # shuffle train data\n",
    "    \n",
    "    X = X.astype('float32')\n",
    "    y = y.astype('float32')\n",
    "    return (X, y)\n",
    "\n",
    "X, y = load()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "skf = StratifiedKFold(y, n_folds=3)\n",
    "y = np_utils.to_categorical(y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (62460, 3, 128, 128))\n",
      "(62460, 'train samples')\n",
      "(6940, 'test samples')\n",
      "Epoch 1/100\n",
      "62460/62460 [==============================] - 784s - loss: 16.0634 - acc: 0.9976 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "62460/62460 [==============================] - 761s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "62460/62460 [==============================] - 760s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "62460/62460 [==============================] - 766s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "62460/62460 [==============================] - 758s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "62460/62460 [==============================] - 757s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "62460/62460 [==============================] - 759s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "62460/62460 [==============================] - 758s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "62460/62460 [==============================] - 763s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "62460/62460 [==============================] - 757s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "62460/62460 [==============================] - 759s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "62460/62460 [==============================] - 757s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "62460/62460 [==============================] - 757s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "62460/62460 [==============================] - 764s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "62460/62460 [==============================] - 758s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "62460/62460 [==============================] - 759s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "62460/62460 [==============================] - 763s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "62460/62460 [==============================] - 759s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "62460/62460 [==============================] - 757s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "62460/62460 [==============================] - 765s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "62460/62460 [==============================] - 756s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "62460/62460 [==============================] - 757s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "62460/62460 [==============================] - 763s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "62460/62460 [==============================] - 758s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "62460/62460 [==============================] - 756s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "62460/62460 [==============================] - 764s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "62460/62460 [==============================] - 755s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "62460/62460 [==============================] - 758s - loss: 16.1181 - acc: 1.0000 - val_loss: 16.1144 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "30720/62460 [=============>................] - ETA: 383s - loss: 16.1181 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/brett/anaconda/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f3cec9316a52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m                         \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                         nb_worker=1)\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/brett/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, show_accuracy, callbacks, validation_data, class_weight, nb_worker)\u001b[0m\n\u001b[0;32m   1021\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1023\u001b[1;33m                         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1024\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "nb_classes = 5\n",
    "accuracy = []\n",
    "nb_epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "for train, test in skf:    \n",
    "    X_train = X[train]\n",
    "    X_test = X[test]\n",
    "    y_train = y[train]\n",
    "    y_test = y[test]\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same',\n",
    "                            input_shape=(3, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(32, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=nb_epochs, show_accuracy=True,\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        nb_worker=1)\n",
    "    \n",
    "    score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    accuracy.append(score[1])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
